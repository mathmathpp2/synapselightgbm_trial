{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# metrics \n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"RegressionModelEvaluation\").getOrCreate()\n",
    "\n",
    "# Load your data\n",
    "data = spark.read.format(\"libsvm\").load(\"path/to/your/data\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Define the models\n",
    "lr = LinearRegression(featuresCol='features', labelCol='label')\n",
    "rf = RandomForestRegressor(featuresCol='features', labelCol='label')\n",
    "gbt = GBTRegressor(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Train the models\n",
    "lr_model = lr.fit(train_data)\n",
    "rf_model = rf.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# Initialize evaluators\n",
    "r2_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"r2\")\n",
    "rmse_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\")\n",
    "mae_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"mae\")\n",
    "mse_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"mse\")\n",
    "\n",
    "# Evaluate the models\n",
    "models = {\n",
    "    \"Linear Regression\": lr_predictions,\n",
    "    \"Random Forest Regressor\": rf_predictions,\n",
    "    \"GBT Regressor\": gbt_predictions\n",
    "}\n",
    "\n",
    "for name, predictions in models.items():\n",
    "    r2 = r2_evaluator.evaluate(predictions)\n",
    "    rmse = rmse_evaluator.evaluate(predictions)\n",
    "    mae = mae_evaluator.evaluate(predictions)\n",
    "    mse = mse_evaluator.evaluate(predictions)\n",
    "    print(f\"{name} Evaluation Metrics:\")\n",
    "    print(f\"R2: {r2}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"GBTRegressorExample\").getOrCreate()\n",
    "\n",
    "# Create the DataFrame\n",
    "data = spark.createDataFrame([\n",
    "    (0, \"red\", \"SUV\", 12, 20.0, 60, 5),\n",
    "    (1, \"blue\", \"sedan\", 9, 30.0, 70, 10),\n",
    "    (2, \"green\", \"truck\", 15, 25.0, 80, 3)\n",
    "], [\"id\", \"color\", \"type\", \"hour\", \"label\", \"milesperhour\", \"age\"])\n",
    "\n",
    "# String Indexing\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"color\", outputCol=\"color_index\"),\n",
    "    StringIndexer(inputCol=\"type\", outputCol=\"type_index\"),\n",
    "    StringIndexer(inputCol=\"hour\", outputCol=\"hour_index\")\n",
    "]\n",
    "\n",
    "# Assembling Features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"color_index\", \"type_index\", \"hour_index\", \"milesperhour\", \"age\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Create and Fit the Pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "model = pipeline.fit(data)\n",
    "transformed_data = model.transform(data)\n",
    "\n",
    "# Training the GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"label\")\n",
    "gbt_model = gbt.fit(transformed_data)\n",
    "\n",
    "# View Transformed Data (Optional)\n",
    "transformed_data.select(\"id\", \"features\", \"label\").show()\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"RegressorExamples\").getOrCreate()\n",
    "\n",
    "# Create the DataFrame\n",
    "data = spark.createDataFrame([\n",
    "    (0, \"red\", \"SUV\", 12, 20.0, 60, 5),\n",
    "    (1, \"blue\", \"sedan\", 9, 30.0, 70, 10),\n",
    "    (2, \"green\", \"truck\", 15, 25.0, 80, 3)\n",
    "], [\"id\", \"color\", \"type\", \"hour\", \"label\", \"milesperhour\", \"age\"])\n",
    "\n",
    "# String Indexing\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"color\", outputCol=\"color_index\"),\n",
    "    StringIndexer(inputCol=\"type\", outputCol=\"type_index\"),\n",
    "    StringIndexer(inputCol=\"hour\", outputCol=\"hour_index\")\n",
    "]\n",
    "\n",
    "# One-Hot Encoding for Linear Regression (not needed for tree-based models)\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[\"color_index\", \"type_index\", \"hour_index\"],\n",
    "    outputCols=[\"color_vec\", \"type_vec\", \"hour_vec\"]\n",
    ")\n",
    "\n",
    "# Assembling Features for Linear Regression\n",
    "assembler_lr = VectorAssembler(\n",
    "    inputCols=[\"color_vec\", \"type_vec\", \"hour_vec\", \"milesperhour\", \"age\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Assembling Features for Tree-Based Models\n",
    "assembler_tree = VectorAssembler(\n",
    "    inputCols=[\"color_index\", \"type_index\", \"hour_index\", \"milesperhour\", \"age\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Create and Fit the Pipeline for Linear Regression\n",
    "pipeline_lr = Pipeline(stages=indexers + [encoder, assembler_lr])\n",
    "model_lr = pipeline_lr.fit(data)\n",
    "transformed_data_lr = model_lr.transform(data)\n",
    "\n",
    "# Create and Fit the Pipeline for Tree-Based Models\n",
    "pipeline_tree = Pipeline(stages=indexers + [assembler_tree])\n",
    "model_tree = pipeline_tree.fit(data)\n",
    "transformed_data_tree = model_tree.transform(data)\n",
    "\n",
    "# Training the Linear Regression Model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "lr_model = lr.fit(transformed_data_lr)\n",
    "\n",
    "# Training the Random Forest Regressor\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")\n",
    "rf_model = rf.fit(transformed_data_tree)\n",
    "\n",
    "# Training the GBT Regressor\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"label\")\n",
    "gbt_model = gbt.fit(transformed_data_tree)\n",
    "\n",
    "# View Transformed Data (Optional)\n",
    "transformed_data_lr.select(\"id\", \"features\", \"label\").show()\n",
    "transformed_data_tree.select(\"id\", \"features\", \"label\").show()\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
