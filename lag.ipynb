{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67910f8d-c4aa-4fe9-a82f-31c448c7baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, split, explode, array, lit, concat_ws, expr, lag\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"LagFeatureExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1af6521f-f597-4ff3-a9b5-60f4efc70519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----+--------+-----------------+---------------+-----------------+---------------+\n",
      "|geohashId|      date|hour|interval|featureA_variance|featureA_median|featureB_variance|featureB_median|\n",
      "+---------+----------+----+--------+-----------------+---------------+-----------------+---------------+\n",
      "|     abcd|2023-08-01|   0|    0-14|                1|             10|                1|              5|\n",
      "|     abcd|2023-08-01|   0|   15-29|                2|             20|                1|              5|\n",
      "|     abcd|2023-08-01|   0|   30-44|                3|             30|                1|              5|\n",
      "|     abcd|2023-08-01|   1|    0-14|                4|             40|                2|              6|\n",
      "|     abcd|2023-08-01|   1|   15-29|                5|             50|                2|              6|\n",
      "|     abcd|2023-08-01|   1|     all|                6|             60|                2|              6|\n",
      "|     abcd|2023-08-01|   2|    0-14|                7|             70|                3|              7|\n",
      "|     abcd|2023-08-01|   2|   15-29|                8|             80|                3|              7|\n",
      "|     abcd|2023-08-01|   2|   30-44|                9|             90|                3|              7|\n",
      "|     abcd|2023-08-01|   2|     all|               10|            100|                4|              8|\n",
      "|     efgh|2023-08-01|   0|    0-14|                1|             10|                1|              5|\n",
      "|     efgh|2023-08-01|   0|   15-29|                2|             20|                1|              5|\n",
      "|     efgh|2023-08-01|   0|   30-44|                3|             30|                1|              5|\n",
      "|     efgh|2023-08-01|   1|    0-14|                4|             40|                2|              6|\n",
      "|     efgh|2023-08-01|   1|   15-29|                5|             50|                2|              6|\n",
      "|     efgh|2023-08-02|   1|     all|                6|             60|                2|              6|\n",
      "|     efgh|2023-08-02|   2|    0-14|                7|             70|                3|              7|\n",
      "|     efgh|2023-08-02|   2|   15-29|                8|             80|                3|              7|\n",
      "|     efgh|2023-08-02|   2|   30-44|                9|             90|                3|              7|\n",
      "|     efgh|2023-08-02|   3|     all|               10|            100|                4|              8|\n",
      "+---------+----------+----+--------+-----------------+---------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example data including \"all\" intervals\n",
    "data = {\n",
    "    \"geohashId\": [\"abcd\", \"abcd\", \"abcd\", \"abcd\", \"abcd\", \"abcd\", \"abcd\", \"abcd\", \"abcd\", \"abcd\",\n",
    "                  \"efgh\", \"efgh\", \"efgh\", \"efgh\", \"efgh\", \"efgh\", \"efgh\", \"efgh\", \"efgh\", \"efgh\"],\n",
    "    \"date\": [\"2023-08-01\", \"2023-08-01\", \"2023-08-01\", \"2023-08-01\", \"2023-08-01\",\n",
    "             \"2023-08-01\", \"2023-08-01\", \"2023-08-01\", \"2023-08-01\", \"2023-08-01\",\n",
    "             \"2023-08-01\", \"2023-08-01\", \"2023-08-01\", \"2023-08-01\", \"2023-08-01\",\n",
    "             \"2023-08-02\", \"2023-08-02\", \"2023-08-02\", \"2023-08-02\", \"2023-08-02\"],\n",
    "    \"hour\": [0, 0, 0, 1, 1, 1, 2, 2, 2, 2,\n",
    "             0, 0, 0, 1, 1, 1, 2, 2, 2, 3],\n",
    "    \"interval\": [\"0-14\", \"15-29\", \"30-44\", \"0-14\", \"15-29\", \"all\", \"0-14\", \"15-29\", \"30-44\", \"all\",\n",
    "                 \"0-14\", \"15-29\", \"30-44\", \"0-14\", \"15-29\", \"all\", \"0-14\", \"15-29\", \"30-44\", \"all\"],\n",
    "    \"featureA_variance\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
    "                          1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"featureA_median\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100,\n",
    "                       10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    \"featureB_variance\": [1, 1, 1, 2, 2, 2, 3, 3, 3, 4,\n",
    "                          1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
    "    \"featureB_median\": [5, 5, 5, 6, 6, 6, 7, 7, 7, 8,\n",
    "                     5, 5, 5, 6, 6, 6, 7, 7, 7, 8]\n",
    "}\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "sdf = spark.createDataFrame(df)\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "3b6486bb-f355-443f-b5c5-c3f09ceeb615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# hourと15minutesのデータに切り分ける\n",
    "sdf_hour = sdf.filter(col(\"interval\") == \"all\")\n",
    "sdf_15min = sdf.filter(col(\"interval\") != \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "7cfac41c-7570-4eb5-ad90-9fd0d063a8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-08-01'"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_date = sdf.agg(F.min('date')).collect()[0][0]\n",
    "first_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a8cc79a4-667d-4e2a-b8e2-5e154c3a9d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-08-02'"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_date = sdf.agg(F.max('date')).collect()[0][0]\n",
    "last_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "c65dee89-1550-403c-9dbb-01e17bc9dd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'unix_timestamp(2023-08-01 00:00:00, yyyy-MM-dd HH:mm:ss)'>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_timestamp = F.unix_timestamp(lit(f\"{first_date} 00:00:00\"))\n",
    "base_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "98960c04-0746-47a7-9f66-0d6bb6ee223d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohashId</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>interval</th>\n",
       "      <th>featureA_variance</th>\n",
       "      <th>featureA_median</th>\n",
       "      <th>featureB_variance</th>\n",
       "      <th>featureB_median</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1690819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2</td>\n",
       "      <td>all</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1690822800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efgh</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1690905600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efgh</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>3</td>\n",
       "      <td>all</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1690912800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohashId        date  hour interval  featureA_variance  featureA_median  \\\n",
       "0      abcd  2023-08-01     1      all                  6               60   \n",
       "1      abcd  2023-08-01     2      all                 10              100   \n",
       "2      efgh  2023-08-02     1      all                  6               60   \n",
       "3      efgh  2023-08-02     3      all                 10              100   \n",
       "\n",
       "   featureB_variance  featureB_median   timestamp  \n",
       "0                  2                6  1690819200  \n",
       "1                  4                8  1690822800  \n",
       "2                  2                6  1690905600  \n",
       "3                  4                8  1690912800  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_hour = sdf_hour.withColumn(\n",
    "    \"timestamp\",\n",
    "    F.unix_timestamp(F.concat(\n",
    "        F.col(\"date\"),\n",
    "        F.lit(\" \"),\n",
    "        F.lpad(F.col(\"hour\").cast(\"string\"), 2, \"0\"),\n",
    "        F.lit(\":00:00\")\n",
    "    ))\n",
    ")\n",
    "\n",
    "sdf_hour.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ab079516-4350-4570-ad4b-6877c9038edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohashId</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>interval</th>\n",
       "      <th>featureA_variance</th>\n",
       "      <th>featureA_median</th>\n",
       "      <th>featureB_variance</th>\n",
       "      <th>featureB_median</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1690819200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2</td>\n",
       "      <td>all</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1690822800</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efgh</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1690905600</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efgh</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>3</td>\n",
       "      <td>all</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1690912800</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohashId        date  hour interval  featureA_variance  featureA_median  \\\n",
       "0      abcd  2023-08-01     1      all                  6               60   \n",
       "1      abcd  2023-08-01     2      all                 10              100   \n",
       "2      efgh  2023-08-02     1      all                  6               60   \n",
       "3      efgh  2023-08-02     3      all                 10              100   \n",
       "\n",
       "   featureB_variance  featureB_median   timestamp  time  \n",
       "0                  2                6  1690819200   1.0  \n",
       "1                  4                8  1690822800   2.0  \n",
       "2                  2                6  1690905600  25.0  \n",
       "3                  4                8  1690912800  27.0  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_hour = sdf_hour.withColumn(\n",
    "    \"time\",\n",
    "    F.round(F.col(\"timestamp\") - base_timestamp) / 3600,\n",
    ")\n",
    "\n",
    "sdf_hour.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "e8f3095c-2ed7-41ae-946a-a371005d75e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohashId</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>interval</th>\n",
       "      <th>featureA_variance</th>\n",
       "      <th>featureA_median</th>\n",
       "      <th>featureB_variance</th>\n",
       "      <th>featureB_median</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0-14</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1690815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>15-29</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1690816500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>30-44</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1690817400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0-14</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1690819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>15-29</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1690820100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohashId        date  hour interval  featureA_variance  featureA_median  \\\n",
       "0      abcd  2023-08-01     0     0-14                  1               10   \n",
       "1      abcd  2023-08-01     0    15-29                  2               20   \n",
       "2      abcd  2023-08-01     0    30-44                  3               30   \n",
       "3      abcd  2023-08-01     1     0-14                  4               40   \n",
       "4      abcd  2023-08-01     1    15-29                  5               50   \n",
       "\n",
       "   featureB_variance  featureB_median   timestamp  \n",
       "0                  1                5  1690815600  \n",
       "1                  1                5  1690816500  \n",
       "2                  1                5  1690817400  \n",
       "3                  2                6  1690819200  \n",
       "4                  2                6  1690820100  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_15min = sdf_15min.withColumn(\n",
    "    \"timestamp\",\n",
    "    F.unix_timestamp(F.concat(\n",
    "        F.col(\"date\"),\n",
    "        F.lit(\" \"),\n",
    "        F.lpad(F.col(\"hour\").cast(\"string\"), 2, \"0\"),\n",
    "        F.lit(\":\"),\n",
    "        F.lpad(F.split(F.col(\"interval\"), '-').getItem(0), 2, \"0\"),\n",
    "        F.lit(\":00\")\n",
    "    ))\n",
    ")\n",
    "\n",
    "sdf_15min.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "4706f32a-7715-4b33-8d67-a2fc225d6add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohashId</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>interval</th>\n",
       "      <th>featureA_variance</th>\n",
       "      <th>featureA_median</th>\n",
       "      <th>featureB_variance</th>\n",
       "      <th>featureB_median</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0-14</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1690815600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>15-29</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1690816500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>30-44</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1690817400</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0-14</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1690819200</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>15-29</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1690820100</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohashId        date  hour interval  featureA_variance  featureA_median  \\\n",
       "0      abcd  2023-08-01     0     0-14                  1               10   \n",
       "1      abcd  2023-08-01     0    15-29                  2               20   \n",
       "2      abcd  2023-08-01     0    30-44                  3               30   \n",
       "3      abcd  2023-08-01     1     0-14                  4               40   \n",
       "4      abcd  2023-08-01     1    15-29                  5               50   \n",
       "\n",
       "   featureB_variance  featureB_median   timestamp  time  \n",
       "0                  1                5  1690815600   0.0  \n",
       "1                  1                5  1690816500   1.0  \n",
       "2                  1                5  1690817400   2.0  \n",
       "3                  2                6  1690819200   4.0  \n",
       "4                  2                6  1690820100   5.0  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_15min = sdf_15min.withColumn(\n",
    "    \"time\",\n",
    "    F.round(F.col(\"timestamp\") - base_timestamp) / 900,\n",
    ")\n",
    "\n",
    "sdf_15min.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "df18fc0b-8041-4564-8de6-2a816edec0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop\n",
    "\n",
    "# # Step 2: Generate a Complete Time Grid\n",
    "# # Generate a list of all 15-minute intervals within a day\n",
    "# # Create a DataFrame with all intervals for each geohashId and date\n",
    "# geohash_ids = sdf.select(\"geohashId\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "# num_dates = len(pd.date_range(first_date, last_date))\n",
    "\n",
    "# complete_hour_grid = []\n",
    "# for geohash in geohash_ids:\n",
    "#     for i in range(num_dates * 24):\n",
    "#         complete_hour_grid.append((geohash, i))\n",
    "\n",
    "# complete_15min_grid = []\n",
    "# for geohash in geohash_ids:\n",
    "#     for i in range(num_dates * 24 * 4):\n",
    "#         complete_15min_grid.append((geohash, i))\n",
    "\n",
    "# schema = StructType([\n",
    "#     StructField(\"geohashId\", StringType(), True),\n",
    "#     StructField(\"time\", IntegerType(), True),\n",
    "# ])\n",
    "\n",
    "# # Join the original dataframe with the complete time grid\n",
    "\n",
    "# complete_hour_df = spark.createDataFrame(pd.DataFrame(complete_hour_grid, columns=[\"geohashId\", \"time\"]), schema)\n",
    "# sdf_hour = complete_hour_df.join(sdf_hour, on=[\"geohashId\", \"time\"], how=\"left\")\n",
    "\n",
    "# complete_15min_df = spark.createDataFrame(pd.DataFrame(complete_15min_grid, columns=[\"geohashId\", \"time\"]), schema)\n",
    "# sdf_15min = complete_15min_df.join(sdf_15min, on=[\"geohashId\", \"time\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "07c37274-87c9-4bba-8c75-94c2eb7d6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross join\n",
    "\n",
    "geohash_ids = sdf.select(\"geohashId\").distinct()\n",
    "times_hours = []\n",
    "for i in range(num_dates * 24):\n",
    "    times_hours.append(i)\n",
    "\n",
    "times_15min = []\n",
    "for i in range(num_dates * 24 * 4):\n",
    "    times_15min.append(i)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"time\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "# Perform cross join between all unique value DataFrames\n",
    "complete_hour_grid = geohash_ids.crossJoin(spark.createDataFrame([(i,) for i in times_hours], schema))\n",
    "complete_15min_grid = geohash_ids.crossJoin(spark.createDataFrame([(i,) for i in times_15min], schema))\n",
    "\n",
    "# Join the original dataframe with the complete time grid\n",
    "\n",
    "sdf_hour = complete_hour_grid.join(sdf_hour, on=[\"geohashId\", \"time\"], how=\"left\")\n",
    "\n",
    "sdf_15min = complete_15min_grid.join(sdf_15min, on=[\"geohashId\", \"time\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "95288e27-8536-45c5-a4c4-97e70784cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with zeros for all columns except the key columns\n",
    "agg_dict = {\n",
    "    \"featureA\": [\"variance\", \"median\"],\n",
    "    \"featureB\": [\"variance\", \"median\"]\n",
    "}\n",
    "value_columns = {f\"{key}_{metric}\" for key, metrics in agg_dict.items() for metric in metrics}\n",
    "fill_dict = {column: 0 for column in value_columns}\n",
    "\n",
    "sdf_hour = sdf_hour.fillna(fill_dict)\n",
    "sdf_15min = sdf_15min.fillna(fill_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "f08fd397-2132-4ec3-89dd-b43f0cdd5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Window Specification\n",
    "\n",
    "# Define the window specification to lag by one interval (15 minutes or one hour)\n",
    "windowSpec = Window.partitionBy('geohashId').orderBy('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "8dfc0d22-0352-4535-a245-7518e6478285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Lag Features for All Specified Value Columns\n",
    "# Create lag features\n",
    "# lag1 = 1 hour ago for sdf_hour, 15 min ago for sdf_15min\n",
    "lag1_exprs = [lag(col_name, 1).over(windowSpec).alias(f'{col_name}_lag1') for col_name in value_columns]\n",
    "# lag4 = 4 hours ago for sdf_hour, 1 hour ago for sdf_15min\n",
    "# lag4_exprs = [lag(col_name, 4).over(windowSpec).alias(f'{col_name}_lag4') for col_name in value_columns]\n",
    "\n",
    "# Select existing columns and add the new lag columns\n",
    "sdf_hour = sdf_hour.select('*', *lag1_exprs)\n",
    "sdf_15min = sdf_15min.select('*', *lag1_exprs)\n",
    "# sdf_15min = sdf_15min.select('*', *lag1_exprs, *lag4_exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "238fc21b-bf49-4127-ba9e-3b0357916205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill any null values that result from lagging at the start of the partitions\n",
    "fill_dict = {f'{column}_lag1': 0 for column in value_columns}\n",
    "# fill_dict4 = {f'{column}_lag4': 0 for column in value_columns}\n",
    "sdf_hour = sdf_hour.fillna(fill_dict)\n",
    "sdf_15min = sdf_15min.fillna(fill_dict)\n",
    "# sdf_15min = sdf_15min.fillna(fill_dict).fillna(fill_dict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "cad1891e-4df7-4668-9a86-4e31f970a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_hour = sdf_hour.orderBy([\"geohashId\", \"time\"])\n",
    "sdf_15min = sdf_15min.orderBy([\"geohashId\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d07c8ce0-604f-4a58-b03c-c9a87d68dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_hour = sdf_hour.withColumn(\n",
    "    \"timestamp\",\n",
    "    F.to_timestamp(base_timestamp + F.col(\"time\") * 3600)\n",
    ")\n",
    "sdf_15min = sdf_15min.withColumn(\n",
    "    \"timestamp\",\n",
    "    F.to_timestamp(base_timestamp + F.col(\"time\") * 900)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "e217b1d7-11db-4c21-aeaf-68849384d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_hour = sdf_hour.filter(col(\"interval\").isNotNull())\n",
    "sdf_15min = sdf_15min.filter(col(\"interval\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "3bcdaf1e-16bc-4e5c-ae72-288845139e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----------------+----------------------+\n",
      "|geohashId|          timestamp|featureA_variance|featureA_variance_lag1|\n",
      "+---------+-------------------+-----------------+----------------------+\n",
      "|     abcd|2023-08-01 01:00:00|                6|                     0|\n",
      "|     abcd|2023-08-01 02:00:00|               10|                     6|\n",
      "|     efgh|2023-08-02 01:00:00|                6|                     0|\n",
      "|     efgh|2023-08-02 03:00:00|               10|                     0|\n",
      "+---------+-------------------+-----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_hour.select(\"geohashId\", \"timestamp\", \"featureA_variance\", \"featureA_variance_lag1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "d81054ef-a2ee-4d87-9499-5f1d66314aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----------------+----------------------+\n",
      "|geohashId|          timestamp|featureA_variance|featureA_variance_lag1|\n",
      "+---------+-------------------+-----------------+----------------------+\n",
      "|     abcd|2023-08-01 00:00:00|                1|                     0|\n",
      "|     abcd|2023-08-01 00:15:00|                2|                     1|\n",
      "|     abcd|2023-08-01 00:30:00|                3|                     2|\n",
      "|     abcd|2023-08-01 01:00:00|                4|                     0|\n",
      "|     abcd|2023-08-01 01:15:00|                5|                     4|\n",
      "|     abcd|2023-08-01 02:00:00|                7|                     0|\n",
      "|     abcd|2023-08-01 02:15:00|                8|                     7|\n",
      "|     abcd|2023-08-01 02:30:00|                9|                     8|\n",
      "|     efgh|2023-08-01 00:00:00|                1|                     0|\n",
      "|     efgh|2023-08-01 00:15:00|                2|                     1|\n",
      "|     efgh|2023-08-01 00:30:00|                3|                     2|\n",
      "|     efgh|2023-08-01 01:00:00|                4|                     0|\n",
      "|     efgh|2023-08-01 01:15:00|                5|                     4|\n",
      "|     efgh|2023-08-02 02:00:00|                7|                     0|\n",
      "|     efgh|2023-08-02 02:15:00|                8|                     7|\n",
      "|     efgh|2023-08-02 02:30:00|                9|                     8|\n",
      "+---------+-------------------+-----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_15min.select(\"geohashId\", \"timestamp\", \"featureA_variance\", \"featureA_variance_lag1\").show()\n",
    "# sdf_15min.select(\"geohashId\", \"timestamp\", \"featureA_variance\", \"featureA_variance_lag1\", \"featureA_variance_lag4\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "dc54019e-9127-4b9e-932e-679c381e2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_union = sdf_hour.union(sdf_15min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "275ed57a-1996-488e-b80e-90edec45332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_union.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f14d5695-2d93-413a-b4ec-ae651a8518ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thama/ghq/github.com/mathmathpp2/synapselightgbm_trial/synapse-test/.venv/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:251: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohashId</th>\n",
       "      <th>time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>featureA_variance</th>\n",
       "      <th>featureA_variance_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abcd</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-01 01:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-08-01 02:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efgh</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-08-02 01:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efgh</td>\n",
       "      <td>27</td>\n",
       "      <td>2023-08-02 03:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohashId  time           timestamp  featureA_variance  \\\n",
       "0      abcd     1 2023-08-01 01:00:00                  6   \n",
       "1      abcd     2 2023-08-01 02:00:00                 10   \n",
       "2      efgh    25 2023-08-02 01:00:00                  6   \n",
       "3      efgh    27 2023-08-02 03:00:00                 10   \n",
       "\n",
       "   featureA_variance_lag1  \n",
       "0                       0  \n",
       "1                       6  \n",
       "2                       0  \n",
       "3                       0  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_union.filter(F.col(\"interval\") == \"all\").orderBy(\"geohashId\", \"time\").toPandas().head(100)[[\"geohashId\", \"time\", \"timestamp\", \"featureA_variance\", \"featureA_variance_lag1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "7ca99535-4bc6-4575-a2db-76dafc24a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thama/ghq/github.com/mathmathpp2/synapselightgbm_trial/synapse-test/.venv/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:251: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohashId</th>\n",
       "      <th>time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>featureA_variance</th>\n",
       "      <th>featureA_variance_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abcd</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abcd</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-01 00:15:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abcd</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-08-01 00:30:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abcd</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-08-01 01:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abcd</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-08-01 01:15:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abcd</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-08-01 02:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abcd</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-08-01 02:15:00</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abcd</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-08-01 02:30:00</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>efgh</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>efgh</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-01 00:15:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>efgh</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-08-01 00:30:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>efgh</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-08-01 01:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>efgh</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-08-01 01:15:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>efgh</td>\n",
       "      <td>104</td>\n",
       "      <td>2023-08-02 02:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>efgh</td>\n",
       "      <td>105</td>\n",
       "      <td>2023-08-02 02:15:00</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>efgh</td>\n",
       "      <td>106</td>\n",
       "      <td>2023-08-02 02:30:00</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geohashId  time           timestamp  featureA_variance  \\\n",
       "0       abcd     0 2023-08-01 00:00:00                  1   \n",
       "1       abcd     1 2023-08-01 00:15:00                  2   \n",
       "2       abcd     2 2023-08-01 00:30:00                  3   \n",
       "3       abcd     4 2023-08-01 01:00:00                  4   \n",
       "4       abcd     5 2023-08-01 01:15:00                  5   \n",
       "5       abcd     8 2023-08-01 02:00:00                  7   \n",
       "6       abcd     9 2023-08-01 02:15:00                  8   \n",
       "7       abcd    10 2023-08-01 02:30:00                  9   \n",
       "8       efgh     0 2023-08-01 00:00:00                  1   \n",
       "9       efgh     1 2023-08-01 00:15:00                  2   \n",
       "10      efgh     2 2023-08-01 00:30:00                  3   \n",
       "11      efgh     4 2023-08-01 01:00:00                  4   \n",
       "12      efgh     5 2023-08-01 01:15:00                  5   \n",
       "13      efgh   104 2023-08-02 02:00:00                  7   \n",
       "14      efgh   105 2023-08-02 02:15:00                  8   \n",
       "15      efgh   106 2023-08-02 02:30:00                  9   \n",
       "\n",
       "    featureA_variance_lag1  \n",
       "0                        0  \n",
       "1                        1  \n",
       "2                        2  \n",
       "3                        0  \n",
       "4                        4  \n",
       "5                        0  \n",
       "6                        7  \n",
       "7                        8  \n",
       "8                        0  \n",
       "9                        1  \n",
       "10                       2  \n",
       "11                       0  \n",
       "12                       4  \n",
       "13                       0  \n",
       "14                       7  \n",
       "15                       8  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_union.filter(F.col(\"interval\") != \"all\").orderBy(\"geohashId\", \"time\").toPandas().head(100)[[\"geohashId\", \"time\", \"timestamp\", \"featureA_variance\", \"featureA_variance_lag1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba90ae-da99-4472-8a84-a000b55d6177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4be440-d3c0-4b4a-9208-a4586f685d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d80d0f-275c-41b2-912a-80b8347322b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2df38f-f03a-4caf-9024-a4f3e8367ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d182e9e-894a-459a-9764-bd393338ff96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
