{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5173f746-1d1b-40f6-93ca-593da53750a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- hour: long (nullable = true)\n",
      " |-- milesperhour: double (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n",
      "+-----+-----+----+\n",
      "|color| type|hour|\n",
      "+-----+-----+----+\n",
      "|  red|  SUV|  12|\n",
      "|  red|sedan|   9|\n",
      "|  red|truck|  15|\n",
      "| blue|  SUV|  20|\n",
      "| blue|sedan|   5|\n",
      "| blue|truck|  10|\n",
      "+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import coalesce, lit\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"ClassifierExamples\").getOrCreate()\n",
    "\n",
    "## ============================================================================\n",
    "## color != label のデータ\n",
    "## ============================================================================\n",
    "# Create the DataFrame\n",
    "data = spark.createDataFrame([\n",
    "    (0, \"red\", \"SUV\", 12, 20.0, 60, 1),\n",
    "    (1, \"red\", \"sedan\", 9, 30.0, 70, 2),\n",
    "    (2, \"red\", \"truck\", 15, 25.0, 80, 3),\n",
    "    (3, \"blue\", \"SUV\", 20, 22.0, 65, 1),\n",
    "    (4, \"blue\", \"sedan\", 5, 35.0, 75, 1),\n",
    "    (5, \"blue\", \"truck\", 10, 28.0, 85, 3),\n",
    "], [\"id\", \"color\", \"type\", \"hour\", \"milesperhour\", \"age\", \"label\"])\n",
    "\n",
    "## ============================================================================\n",
    "## color = label のデータ\n",
    "## ============================================================================\n",
    "# Create the DataFrame\n",
    "# data = spark.createDataFrame([\n",
    "#     (0, \"red\", \"SUV\", 12, 20.0, 60, 1),\n",
    "#     (1, \"blue\", \"sedan\", 9, 30.0, 70, 2),\n",
    "#     (2, \"red\", \"truck\", 15, 25.0, 80, 1),\n",
    "#     (3, \"blue\", \"SUV\", 20, 22.0, 65, 2),\n",
    "#     (4, \"red\", \"sedan\", 5, 35.0, 75, 1),\n",
    "#     (5, \"blue\", \"truck\", 10, 28.0, 85, 2),\n",
    "# ], [\"id\", \"color\", \"type\", \"hour\", \"milesperhour\", \"age\", \"label\"])\n",
    "\n",
    "\n",
    "# Drop rows with any null values\n",
    "data = data.dropna()\n",
    "\n",
    "# Debugging: Print schema and check for nulls in specific columns\n",
    "data.printSchema()\n",
    "data.select(\"color\", \"type\", \"hour\").show()\n",
    "\n",
    "# Fill nulls in categorical columns with 'missing'\n",
    "data = data.withColumn(\"color\", coalesce(data[\"color\"], lit(\"missing\")))\n",
    "data = data.withColumn(\"type\", coalesce(data[\"type\"], lit(\"missing\")))\n",
    "\n",
    "# Convert string labels to numeric\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "data = label_indexer.fit(data).transform(data)\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% test)\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# String Indexing for features\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"color\", outputCol=\"color_index\"),\n",
    "    StringIndexer(inputCol=\"type\", outputCol=\"type_index\"),\n",
    "    StringIndexer(inputCol=\"hour\", outputCol=\"hour_index\")\n",
    "]\n",
    "\n",
    "# One-Hot Encoding for Logistic Regression (not needed for tree-based models)\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[\"color_index\", \"type_index\", \"hour_index\"],\n",
    "    outputCols=[\"color_vec\", \"type_vec\", \"hour_vec\"]\n",
    ")\n",
    "\n",
    "# Assembling Features for Logistic Regression and Naive Bayes\n",
    "assembler_lr_nb = VectorAssembler(\n",
    "    inputCols=[\"color_vec\", \"type_vec\", \"hour_vec\", \"milesperhour\", \"age\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Assembling Features for Tree-Based Models\n",
    "assembler_tree = VectorAssembler(\n",
    "    inputCols=[\"color_index\", \"type_index\", \"hour_index\", \"milesperhour\", \"age\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Create and Fit the Pipeline for Logistic Regression and Naive Bayes\n",
    "pipeline_lr_nb = Pipeline(stages=indexers + [encoder, assembler_lr_nb])\n",
    "model_lr_nb = pipeline_lr_nb.fit(train_data)\n",
    "transformed_train_data_lr_nb = model_lr_nb.transform(train_data)\n",
    "transformed_test_data_lr_nb = model_lr_nb.transform(test_data)\n",
    "\n",
    "# Create and Fit the Pipeline for Tree-Based Models\n",
    "pipeline_tree = Pipeline(stages=indexers + [assembler_tree])\n",
    "model_tree = pipeline_tree.fit(train_data)\n",
    "transformed_train_data_tree = model_tree.transform(train_data)\n",
    "transformed_test_data_tree = model_tree.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb015b-97f1-4b01-b0f2-e1395b57c35f",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6f3531c-cca9-4321-8c0b-f00cb5793f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Logistic Regression Model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "lr_model = lr.fit(transformed_train_data_lr_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2020b2e6-e9cc-472b-aeed-7d479545214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイプラインで処理した pyspark データフレームから、features の順番で特徴量を取り出す\n",
    "def get_features(df):\n",
    "    feature_attrs = df.schema['features'].metadata['ml_attr']['attrs']\n",
    "    features = []\n",
    "    for attr_type, attrs in feature_attrs.items():\n",
    "        features += attrs\n",
    "\n",
    "    for each in sorted(features, key=lambda x: x['idx']):\n",
    "        print(each['idx'], each['name'])\n",
    "    \n",
    "    feature_names = [each['name'] for each in sorted(features, key=lambda x: x['idx'])]\n",
    "\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8303b02b-be49-488a-bb47-d454c42a0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# これはたぶんエラーになるのでかわりに次のセルを実行\n",
    "\n",
    "# # Get model coefficients and intercept for Logistic Regression\n",
    "# coefficients = lr_model.coefficients\n",
    "# intercept = lr_model.intercept\n",
    "# print(f\"Coefficients: {coefficients}\")\n",
    "# print(f\"Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "465b0e56-a5aa-415b-af35-072c197945d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: DenseMatrix([[ 2.19021458e+00,  2.04738613e+00, -8.34716427e+00,\n",
      "              -7.03965340e+00,  2.19577114e+00, -5.48109301e+00,\n",
      "               8.75308059e-01,  3.46509751e-01, -2.59519343e-01],\n",
      "             [-2.16080475e+00, -2.17598618e+00,  8.22498412e+00,\n",
      "               6.98902753e+00, -2.10724153e+00,  5.34844865e+00,\n",
      "              -1.15673774e+00, -3.23254873e-01,  2.60108872e-01],\n",
      "             [-2.94098344e-02,  1.28600044e-01,  1.22180156e-01,\n",
      "               5.06258718e-02, -8.85296105e-02,  1.32644362e-01,\n",
      "               2.81429676e-01, -2.32548774e-02, -5.89529440e-04]])\n",
      "Intercept: [18.255972365913973,-12.515273657784677,-5.740698708129297]\n"
     ]
    }
   ],
   "source": [
    "# Get model coefficients and intercept for Logistic Regression\n",
    "coefficients = lr_model.coefficientMatrix\n",
    "intercept = lr_model.interceptVector\n",
    "print(f\"Coefficients: {coefficients}\")\n",
    "print(f\"Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e51b2793-848e-4dd7-afcc-62669c17caa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape = num_classes x num_features\n",
    "np.array(coefficients.toArray().tolist()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "422423dc-197b-4ea2-9d14-42529b5aaba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 color_vec_blue\n",
      "1 type_vec_SUV\n",
      "2 type_vec_truck\n",
      "3 hour_vec_10\n",
      "4 hour_vec_12\n",
      "5 hour_vec_15\n",
      "6 hour_vec_20\n",
      "7 milesperhour\n",
      "8 age\n"
     ]
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(\n",
    "    np.array(coefficients.toArray().tolist()),\n",
    "    columns=get_features(transformed_train_data_lr_nb)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17187e70-8b7f-4135-a028-f187824da5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color_vec_blue</th>\n",
       "      <th>type_vec_SUV</th>\n",
       "      <th>type_vec_truck</th>\n",
       "      <th>hour_vec_10</th>\n",
       "      <th>hour_vec_12</th>\n",
       "      <th>hour_vec_15</th>\n",
       "      <th>hour_vec_20</th>\n",
       "      <th>milesperhour</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.190215</td>\n",
       "      <td>2.047386</td>\n",
       "      <td>-8.347164</td>\n",
       "      <td>-7.039653</td>\n",
       "      <td>2.195771</td>\n",
       "      <td>-5.481093</td>\n",
       "      <td>0.875308</td>\n",
       "      <td>0.346510</td>\n",
       "      <td>-0.259519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.160805</td>\n",
       "      <td>-2.175986</td>\n",
       "      <td>8.224984</td>\n",
       "      <td>6.989028</td>\n",
       "      <td>-2.107242</td>\n",
       "      <td>5.348449</td>\n",
       "      <td>-1.156738</td>\n",
       "      <td>-0.323255</td>\n",
       "      <td>0.260109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.029410</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.122180</td>\n",
       "      <td>0.050626</td>\n",
       "      <td>-0.088530</td>\n",
       "      <td>0.132644</td>\n",
       "      <td>0.281430</td>\n",
       "      <td>-0.023255</td>\n",
       "      <td>-0.000590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color_vec_blue  type_vec_SUV  type_vec_truck  hour_vec_10  hour_vec_12  \\\n",
       "0        2.190215      2.047386       -8.347164    -7.039653     2.195771   \n",
       "1       -2.160805     -2.175986        8.224984     6.989028    -2.107242   \n",
       "2       -0.029410      0.128600        0.122180     0.050626    -0.088530   \n",
       "\n",
       "   hour_vec_15  hour_vec_20  milesperhour       age  \n",
       "0    -5.481093     0.875308      0.346510 -0.259519  \n",
       "1     5.348449    -1.156738     -0.323255  0.260109  \n",
       "2     0.132644     0.281430     -0.023255 -0.000590  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99885ab3-0428-44c6-9f71-e7501c9ddb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  label_index\n",
       "0      1          0.0\n",
       "1      2          2.0\n",
       "2      3          1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インデックスと label の対応\n",
    "data.toPandas()[['label', 'label_index']].drop_duplicates().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a441659-18ae-4a43-a0ce-c68dc2c9d5df",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04d809de-ac10-4f03-9f1b-12945e87bf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/17 00:37:29 WARN DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 5 (= number of training instances)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Importance\n",
      "4           age    0.574963\n",
      "3  milesperhour    0.233631\n",
      "1    type_index    0.128906\n",
      "2    hour_index    0.062500\n",
      "0   color_index    0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Get model summary to extract training metrics for Logistic Regression\n",
    "# training_summary = lr_model.summary\n",
    "# print(f\"Training Accuracy: {training_summary.accuracy}\")\n",
    "# print(f\"Training Precision: {training_summary.precisionByLabel}\")\n",
    "# print(f\"Training Recall: {training_summary.recallByLabel}\")\n",
    "# print(f\"Training F1 Score: {training_summary.fMeasureByLabel()}\")\n",
    "\n",
    "# Training the Random Forest Classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "rf_model = rf.fit(transformed_train_data_tree)\n",
    "\n",
    "# # Training the GBT Classifier\n",
    "# gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "# gbt_model = gbt.fit(transformed_train_data_tree)\n",
    "\n",
    "# # Training the Naive Bayes Classifier\n",
    "# nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "# nb_model = nb.fit(transformed_train_data_lr_nb)\n",
    "\n",
    "# # Initialize evaluators for all models\n",
    "# evaluator_accuracy = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"accuracy\")\n",
    "# evaluator_precision = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"weightedPrecision\")\n",
    "# evaluator_recall = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"weightedRecall\")\n",
    "# evaluator_f1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"f1\")\n",
    "\n",
    "# # Evaluating the Logistic Regression Model\n",
    "# lr_predictions = lr_model.transform(transformed_test_data_lr_nb)\n",
    "# lr_accuracy = evaluator_accuracy.evaluate(lr_predictions)\n",
    "# lr_precision = evaluator_precision.evaluate(lr_predictions)\n",
    "# lr_recall = evaluator_recall.evaluate(lr_predictions)\n",
    "# lr_f1 = evaluator_f1.evaluate(lr_predictions)\n",
    "# print(f\"Logistic Regression Accuracy: {lr_accuracy}\")\n",
    "# print(f\"Logistic Regression Precision: {lr_precision}\")\n",
    "# print(f\"Logistic Regression Recall: {lr_recall}\")\n",
    "# print(f\"Logistic Regression F1 Score: {lr_f1}\")\n",
    "\n",
    "# # Evaluating the Random Forest Classifier\n",
    "# rf_predictions = rf_model.transform(transformed_test_data_tree)\n",
    "# rf_accuracy = evaluator_accuracy.evaluate(rf_predictions)\n",
    "# rf_precision = evaluator_precision.evaluate(rf_predictions)\n",
    "# rf_recall = evaluator_recall.evaluate(rf_predictions)\n",
    "# rf_f1 = evaluator_f1.evaluate(rf_predictions)\n",
    "# print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
    "# print(f\"Random Forest Precision: {rf_precision}\")\n",
    "# print(f\"Random Forest Recall: {rf_recall}\")\n",
    "# print(f\"Random Forest F1 Score: {rf_f1}\")\n",
    "\n",
    "# Get feature importances for Random Forest\n",
    "rf_feature_importances = rf_model.featureImportances.toArray()\n",
    "features_importances_rf = [(assembler_tree.getInputCols()[i], float(rf_feature_importances[i])) for i in range(len(rf_feature_importances))]\n",
    "importances_df_rf = pd.DataFrame(features_importances_rf, columns=[\"Feature\", \"Importance\"]).sort_values(by='Importance', ascending=False)\n",
    "print(importances_df_rf)\n",
    "\n",
    "# # Evaluating the GBT Classifier\n",
    "# gbt_predictions = gbt_model.transform(transformed_test_data_tree)\n",
    "# gbt_accuracy = evaluator_accuracy.evaluate(gbt_predictions)\n",
    "# gbt_precision = evaluator_precision.evaluate(gbt_predictions)\n",
    "# gbt_recall = evaluator_recall.evaluate(gbt_predictions)\n",
    "# gbt_f1 = evaluator_f1.evaluate(gbt_predictions)\n",
    "# print(f\"GBT Classifier Accuracy: {gbt_accuracy}\")\n",
    "# print(f\"GBT Classifier Precision: {gbt_precision}\")\n",
    "# print(f\"GBT Classifier Recall: {gbt_recall}\")\n",
    "# print(f\"GBT Classifier F1 Score: {gbt_f1}\")\n",
    "\n",
    "# # Get feature importances for GBT\n",
    "# gbt_feature_importances = gbt_model.featureImportances.toArray()\n",
    "# features_importances_gbt = [(assembler_tree.getInputCols()[i], float(gbt_feature_importances[i])) for i in range(len(gbt_feature_importances))]\n",
    "# importances_df_gbt = pd.DataFrame(features_importances_gbt, columns=[\"Feature\", \"Importance\"]).sort_values(by='Importance', ascending=False)\n",
    "# print(importances_df_gbt)\n",
    "\n",
    "# # Evaluating the Naive Bayes Classifier\n",
    "# nb_predictions = nb_model.transform(transformed_test_data_lr_nb)\n",
    "# nb_accuracy = evaluator_accuracy.evaluate(nb_predictions)\n",
    "# nb_precision = evaluator_precision.evaluate(nb_predictions)\n",
    "# nb_recall = evaluator_recall.evaluate(nb_predictions)\n",
    "# nb_f1 = evaluator_f1.evaluate(nb_predictions)\n",
    "# print(f\"Naive Bayes Accuracy: {nb_accuracy}\")\n",
    "# print(f\"Naive Bayes Precision: {nb_precision}\")\n",
    "# print(f\"Naive Bayes Recall: {nb_recall}\")\n",
    "# print(f\"Naive Bayes F1 Score: {nb_f1}\")\n",
    "\n",
    "# # Naive Bayes Model Parameters\n",
    "# print(f\"Naive Bayes Model Parameters: {nb_model.explainParams()}\")\n",
    "\n",
    "# # Extract and print class prior probabilities and conditional probabilities for Naive Bayes\n",
    "# class_prior_probs = np.exp(nb_model.pi.toArray())\n",
    "# conditional_probs = np.exp(nb_model.theta.toArray())\n",
    "\n",
    "# # Get the number of classes and features\n",
    "# num_classes, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f0eb0-df6f-4e0e-9872-bac946841536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
