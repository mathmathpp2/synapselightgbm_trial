{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5173f746-1d1b-40f6-93ca-593da53750a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/17 00:02:13 WARN Utils: Your hostname, thamaMBP.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)\n",
      "24/07/17 00:02:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/17 00:02:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/07/17 00:02:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/07/17 00:02:14 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/07/17 00:02:14 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- hour: long (nullable = true)\n",
      " |-- milesperhour: double (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- _8: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+\n",
      "|color| type|hour|\n",
      "+-----+-----+----+\n",
      "|  red|  SUV|  12|\n",
      "| blue|sedan|   9|\n",
      "|  red|truck|  15|\n",
      "| blue|  SUV|  20|\n",
      "|  red|sedan|   5|\n",
      "| blue|truck|  10|\n",
      "+-----+-----+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/17 00:02:29 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o688.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:1085)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m lr_model \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mfit(transformed_train_data_lr_nb)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Get model coefficients and intercept for Logistic Regression\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m \u001b[43mlr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoefficients\u001b[49m\n\u001b[1;32m    101\u001b[0m intercept \u001b[38;5;241m=\u001b[39m lr_model\u001b[38;5;241m.\u001b[39mintercept\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficients: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoefficients\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ghq/github.com/mathmathpp2/synapselightgbm_trial/synapse-test/.venv/lib/python3.11/site-packages/pyspark/ml/classification.py:1537\u001b[0m, in \u001b[0;36mLogisticRegressionModel.coefficients\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;129m@property\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;129m@since\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoefficients\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Vector:\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;124;03m    Model coefficients of binomial logistic regression.\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03m    An exception is thrown in the case of multinomial logistic regression.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_java\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoefficients\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ghq/github.com/mathmathpp2/synapselightgbm_trial/synapse-test/.venv/lib/python3.11/site-packages/pyspark/ml/wrapper.py:72\u001b[0m, in \u001b[0;36mJavaWrapper._call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m java_args \u001b[38;5;241m=\u001b[39m [_py2java(sc, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _java2py(sc, \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjava_args\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/ghq/github.com/mathmathpp2/synapselightgbm_trial/synapse-test/.venv/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/ghq/github.com/mathmathpp2/synapselightgbm_trial/synapse-test/.venv/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/ghq/github.com/mathmathpp2/synapselightgbm_trial/synapse-test/.venv/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o688.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:1085)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import coalesce, lit\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"ClassifierExamples\").getOrCreate()\n",
    "\n",
    "# Create the DataFrame\n",
    "# data = spark.createDataFrame([\n",
    "#     (0, \"red\", \"SUV\", 12, 20.0, 60, 5, \"yes\"),\n",
    "#     (1, \"blue\", \"sedan\", 9, 30.0, 70, 10, \"no\"),\n",
    "#     (2, \"green\", \"truck\", 15, 25.0, 80, 3, \"yes\"),\n",
    "#     (3, \"yellow\", \"SUV\", 20, 22.0, 65, 6, \"no\"),\n",
    "#     (4, \"white\", \"sedan\", 5, 35.0, 75, 12, \"yes\"),\n",
    "#     (5, \"black\", \"truck\", 10, 28.0, 85, 7, \"no\"),\n",
    "#     # (6, None, \"sedan\", 8, None, 70, 9, \"yes\"),  # Example with null values\n",
    "#     # (7, \"blue\", None, 5, 30.0, None, 4, \"yes\")\n",
    "# ], [\"id\", \"color\", \"type\", \"hour\", \"milesperhour\", \"age\", \"label\"])\n",
    "\n",
    "## ============================================================================\n",
    "## color=label のデータ\n",
    "## ============================================================================\n",
    "data = spark.createDataFrame([\n",
    "    (0, \"red\", \"SUV\", 12, 20.0, 60, 5, \"yes\"),\n",
    "    (1, \"blue\", \"sedan\", 9, 30.0, 70, 10, \"no\"),\n",
    "    (2, \"red\", \"truck\", 15, 25.0, 80, 3, \"yes\"),\n",
    "    (3, \"blue\", \"SUV\", 20, 22.0, 65, 6, \"no\"),\n",
    "    (4, \"red\", \"sedan\", 5, 35.0, 75, 12, \"yes\"),\n",
    "    (5, \"blue\", \"truck\", 10, 28.0, 85, 7, \"no\"),\n",
    "    # (6, None, \"sedan\", 8, None, 70, 9, \"yes\"),  # Example with null values\n",
    "    # (7, \"blue\", None, 5, 30.0, None, 4, \"yes\")\n",
    "], [\"id\", \"color\", \"type\", \"hour\", \"milesperhour\", \"age\", \"label\"])\n",
    "\n",
    "\n",
    "# Drop rows with any null values\n",
    "data = data.dropna()\n",
    "\n",
    "# Debugging: Print schema and check for nulls in specific columns\n",
    "data.printSchema()\n",
    "data.select(\"color\", \"type\", \"hour\").show()\n",
    "\n",
    "# Fill nulls in categorical columns with 'missing'\n",
    "data = data.withColumn(\"color\", coalesce(data[\"color\"], lit(\"missing\")))\n",
    "data = data.withColumn(\"type\", coalesce(data[\"type\"], lit(\"missing\")))\n",
    "\n",
    "# Convert string labels to numeric\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "data = label_indexer.fit(data).transform(data)\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% test)\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# String Indexing for features\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"color\", outputCol=\"color_index\"),\n",
    "    StringIndexer(inputCol=\"type\", outputCol=\"type_index\"),\n",
    "    StringIndexer(inputCol=\"hour\", outputCol=\"hour_index\")\n",
    "]\n",
    "\n",
    "# One-Hot Encoding for Logistic Regression (not needed for tree-based models)\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[\"color_index\", \"type_index\", \"hour_index\"],\n",
    "    outputCols=[\"color_vec\", \"type_vec\", \"hour_vec\"]\n",
    ")\n",
    "\n",
    "# Assembling Features for Logistic Regression and Naive Bayes\n",
    "assembler_lr_nb = VectorAssembler(\n",
    "    inputCols=[\"color_vec\", \"type_vec\", \"hour_vec\", \"milesperhour\", \"age\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Assembling Features for Tree-Based Models\n",
    "assembler_tree = VectorAssembler(\n",
    "    inputCols=[\"color_index\", \"type_index\", \"hour_index\", \"milesperhour\", \"age\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Create and Fit the Pipeline for Logistic Regression and Naive Bayes\n",
    "pipeline_lr_nb = Pipeline(stages=indexers + [encoder, assembler_lr_nb])\n",
    "model_lr_nb = pipeline_lr_nb.fit(train_data)\n",
    "transformed_train_data_lr_nb = model_lr_nb.transform(train_data)\n",
    "transformed_test_data_lr_nb = model_lr_nb.transform(test_data)\n",
    "\n",
    "# Create and Fit the Pipeline for Tree-Based Models\n",
    "pipeline_tree = Pipeline(stages=indexers + [assembler_tree])\n",
    "model_tree = pipeline_tree.fit(train_data)\n",
    "transformed_train_data_tree = model_tree.transform(train_data)\n",
    "transformed_test_data_tree = model_tree.transform(test_data)\n",
    "\n",
    "# # Training the Logistic Regression Model\n",
    "# lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "# lr_model = lr.fit(transformed_train_data_lr_nb)\n",
    "\n",
    "# # Get model coefficients and intercept for Logistic Regression\n",
    "# coefficients = lr_model.coefficients\n",
    "# intercept = lr_model.intercept\n",
    "# print(f\"Coefficients: {coefficients}\")\n",
    "# print(f\"Intercept: {intercept}\")\n",
    "\n",
    "# # Get model summary to extract training metrics for Logistic Regression\n",
    "# training_summary = lr_model.summary\n",
    "# print(f\"Training Accuracy: {training_summary.accuracy}\")\n",
    "# print(f\"Training Precision: {training_summary.precisionByLabel}\")\n",
    "# print(f\"Training Recall: {training_summary.recallByLabel}\")\n",
    "# print(f\"Training F1 Score: {training_summary.fMeasureByLabel()}\")\n",
    "\n",
    "# Training the Random Forest Classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "rf_model = rf.fit(transformed_train_data_tree)\n",
    "\n",
    "# # Training the GBT Classifier\n",
    "# gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "# gbt_model = gbt.fit(transformed_train_data_tree)\n",
    "\n",
    "# # Training the Naive Bayes Classifier\n",
    "# nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "# nb_model = nb.fit(transformed_train_data_lr_nb)\n",
    "\n",
    "# Initialize evaluators for all models\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"accuracy\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"weightedRecall\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"f1\")\n",
    "\n",
    "# # Evaluating the Logistic Regression Model\n",
    "# lr_predictions = lr_model.transform(transformed_test_data_lr_nb)\n",
    "# lr_accuracy = evaluator_accuracy.evaluate(lr_predictions)\n",
    "# lr_precision = evaluator_precision.evaluate(lr_predictions)\n",
    "# lr_recall = evaluator_recall.evaluate(lr_predictions)\n",
    "# lr_f1 = evaluator_f1.evaluate(lr_predictions)\n",
    "# print(f\"Logistic Regression Accuracy: {lr_accuracy}\")\n",
    "# print(f\"Logistic Regression Precision: {lr_precision}\")\n",
    "# print(f\"Logistic Regression Recall: {lr_recall}\")\n",
    "# print(f\"Logistic Regression F1 Score: {lr_f1}\")\n",
    "\n",
    "# Evaluating the Random Forest Classifier\n",
    "rf_predictions = rf_model.transform(transformed_test_data_tree)\n",
    "rf_accuracy = evaluator_accuracy.evaluate(rf_predictions)\n",
    "rf_precision = evaluator_precision.evaluate(rf_predictions)\n",
    "rf_recall = evaluator_recall.evaluate(rf_predictions)\n",
    "rf_f1 = evaluator_f1.evaluate(rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
    "print(f\"Random Forest Precision: {rf_precision}\")\n",
    "print(f\"Random Forest Recall: {rf_recall}\")\n",
    "print(f\"Random Forest F1 Score: {rf_f1}\")\n",
    "\n",
    "# Get feature importances for Random Forest\n",
    "rf_feature_importances = rf_model.featureImportances.toArray()\n",
    "features_importances_rf = [(assembler_tree.getInputCols()[i], float(rf_feature_importances[i])) for i in range(len(rf_feature_importances))]\n",
    "importances_df_rf = pd.DataFrame(features_importances_rf, columns=[\"Feature\", \"Importance\"]).sort_values(by='Importance', ascending=False)\n",
    "print(importances_df_rf)\n",
    "\n",
    "# # Evaluating the GBT Classifier\n",
    "# gbt_predictions = gbt_model.transform(transformed_test_data_tree)\n",
    "# gbt_accuracy = evaluator_accuracy.evaluate(gbt_predictions)\n",
    "# gbt_precision = evaluator_precision.evaluate(gbt_predictions)\n",
    "# gbt_recall = evaluator_recall.evaluate(gbt_predictions)\n",
    "# gbt_f1 = evaluator_f1.evaluate(gbt_predictions)\n",
    "# print(f\"GBT Classifier Accuracy: {gbt_accuracy}\")\n",
    "# print(f\"GBT Classifier Precision: {gbt_precision}\")\n",
    "# print(f\"GBT Classifier Recall: {gbt_recall}\")\n",
    "# print(f\"GBT Classifier F1 Score: {gbt_f1}\")\n",
    "\n",
    "# # Get feature importances for GBT\n",
    "# gbt_feature_importances = gbt_model.featureImportances.toArray()\n",
    "# features_importances_gbt = [(assembler_tree.getInputCols()[i], float(gbt_feature_importances[i])) for i in range(len(gbt_feature_importances))]\n",
    "# importances_df_gbt = pd.DataFrame(features_importances_gbt, columns=[\"Feature\", \"Importance\"]).sort_values(by='Importance', ascending=False)\n",
    "# print(importances_df_gbt)\n",
    "\n",
    "# # Evaluating the Naive Bayes Classifier\n",
    "# nb_predictions = nb_model.transform(transformed_test_data_lr_nb)\n",
    "# nb_accuracy = evaluator_accuracy.evaluate(nb_predictions)\n",
    "# nb_precision = evaluator_precision.evaluate(nb_predictions)\n",
    "# nb_recall = evaluator_recall.evaluate(nb_predictions)\n",
    "# nb_f1 = evaluator_f1.evaluate(nb_predictions)\n",
    "# print(f\"Naive Bayes Accuracy: {nb_accuracy}\")\n",
    "# print(f\"Naive Bayes Precision: {nb_precision}\")\n",
    "# print(f\"Naive Bayes Recall: {nb_recall}\")\n",
    "# print(f\"Naive Bayes F1 Score: {nb_f1}\")\n",
    "\n",
    "# # Naive Bayes Model Parameters\n",
    "# print(f\"Naive Bayes Model Parameters: {nb_model.explainParams()}\")\n",
    "\n",
    "# # Extract and print class prior probabilities and conditional probabilities for Naive Bayes\n",
    "# class_prior_probs = np.exp(nb_model.pi.toArray())\n",
    "# conditional_probs = np.exp(nb_model.theta.toArray())\n",
    "\n",
    "# # Get the number of classes and features\n",
    "# num_classes, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f0eb0-df6f-4e0e-9872-bac946841536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
