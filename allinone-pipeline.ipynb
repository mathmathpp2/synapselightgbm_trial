{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa0d5357-a45a-470e-bd07-c5f66297e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pyspark.sql.functions import coalesce, lit, rand\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegressionModel, RandomForestClassificationModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "154a5722-0545-47e7-a7ea-cd5d856b66d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=MyApp, master=local[*]) created by __init__ at /var/folders/w_/hg905l611296df772h1275kr0000gn/T/ipykernel_37179/2579216408.py:13 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m packages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg.apache.hadoop:hadoop-aws:3.3.4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg.apache.hadoop:hadoop-client-api:3.3.4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg.apache.hadoop:hadoop-client-runtime:3.3.4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      7\u001b[0m conf \u001b[38;5;241m=\u001b[39m SparkConf() \\\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39msetAppName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMyApp\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.driver.memory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8g\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.executor.memory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8g\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.jars.packages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(packages))\n\u001b[0;32m---> 13\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m hadoop_config \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39mhadoopConfiguration()\n\u001b[1;32m     16\u001b[0m hadoop_config\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfs.s3a.impl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg.apache.hadoop.fs.s3a.S3AFileSystem\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/ghq/github.com/mathmathpp2/synapselightgbm_trial/synapse-test/.venv/lib/python3.11/site-packages/pyspark/context.py:198\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m     )\n\u001b[0;32m--> 198\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    201\u001b[0m         master,\n\u001b[1;32m    202\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m         memory_profiler_cls,\n\u001b[1;32m    213\u001b[0m     )\n",
      "File \u001b[0;32m~/ghq/github.com/mathmathpp2/synapselightgbm_trial/synapse-test/.venv/lib/python3.11/site-packages/pyspark/context.py:445\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    442\u001b[0m     callsite \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\u001b[38;5;241m.\u001b[39m_callsite\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m# Raise error if there is already a running Spark context\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot run multiple SparkContexts at once; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting SparkContext(app=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, master=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    450\u001b[0m             currentAppName,\n\u001b[1;32m    451\u001b[0m             currentMaster,\n\u001b[1;32m    452\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[1;32m    453\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfile,\n\u001b[1;32m    454\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mlinenum,\n\u001b[1;32m    455\u001b[0m         )\n\u001b[1;32m    456\u001b[0m     )\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;241m=\u001b[39m instance\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=MyApp, master=local[*]) created by __init__ at /var/folders/w_/hg905l611296df772h1275kr0000gn/T/ipykernel_37179/2579216408.py:13 "
     ]
    }
   ],
   "source": [
    "packages = [\n",
    "    'org.apache.hadoop:hadoop-aws:3.3.4',\n",
    "    'org.apache.hadoop:hadoop-client-api:3.3.4',\n",
    "    'org.apache.hadoop:hadoop-client-runtime:3.3.4',\n",
    "]\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(\"MyApp\") \\\n",
    "    .set(\"spark.driver.memory\", \"8g\") \\\n",
    "    .set(\"spark.executor.memory\", \"8g\") \\\n",
    "    .set('spark.jars.packages', ','.join(packages))\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_config = sc._jsc.hadoopConfiguration()\n",
    "hadoop_config.set('fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    "hadoop_config.set('com.amazonaws.services.s3.enableV4', 'true')\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d153dbc-e686-4e2a-bc5c-27ab8de9ee4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MyApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10c2ebd10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb7cbf26-cb8d-42c0-b471-a5d13497ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+----+------------------+---+-----+----------+-----------+\n",
      "| id|color| type|hour|      milesperhour|age|label|      date|    geohash|\n",
      "+---+-----+-----+----+------------------+---+-----+----------+-----------+\n",
      "|  0| blue|sedan|   2| 23.85204602239879| 41|    2|2024-07-02|u0jvfxosqr5|\n",
      "|  1|green|sedan|   2|20.295620865550074| 81|    3|2024-07-02|7cbzbn6kgxg|\n",
      "|  2|  red|truck|   2| 33.61090496536134| 70|    1|2024-07-01|3w70knmoobn|\n",
      "|  3| blue|truck|   4|33.141766706752065| 65|    2|2024-07-04|lbkoduj9ff9|\n",
      "|  4|green|  SUV|   2|22.608227456451203| 70|    3|2024-07-03|vqzx4onq15q|\n",
      "|  5|green|truck|   2|19.094984118957022| 60|    3|2024-07-01|9dh9s0c2mf6|\n",
      "|  6|green|sedan|   4| 28.02709350819081| 46|    2|2024-07-03|y15n01iyey8|\n",
      "|  7|green|truck|   4| 21.76558467703689| 52|    3|2024-07-01|og9gtht2xu0|\n",
      "|  8| blue|truck|   0|31.203967505819808| 61|    2|2024-07-04|d0rqn1z6dg1|\n",
      "|  9|green|  SUV|   3| 27.15535647554013| 65|    3|2024-07-01|l569mbxs13p|\n",
      "| 10|  red|sedan|   0| 24.91081759211126| 74|    1|2024-07-03|9bwik8m46f7|\n",
      "| 11|green|sedan|   0|29.660580790321184| 57|    2|2024-07-04|dv5sp2b1coj|\n",
      "| 12|green|  SUV|   4|  31.5914850663209| 64|    3|2024-07-03|wqjjhq603f1|\n",
      "| 13|green|truck|   2|24.636219617837604| 43|    3|2024-07-03|kfqv4disa4f|\n",
      "| 14| blue|truck|   1|31.468588092255374| 85|    3|2024-07-02|2aagkeiy80y|\n",
      "| 15|  red|sedan|   2| 19.10922523484837| 40|    1|2024-07-02|0zjitw1ch0h|\n",
      "| 16| blue|truck|   0|28.784203830820093| 84|    2|2024-07-01|fomo974pvtr|\n",
      "| 17| blue|  SUV|   2|23.173104761224135| 63|    2|2024-07-02|b9zsoqbriom|\n",
      "| 18|  red|  SUV|   4| 32.80531345258878| 52|    1|2024-07-02|im1rax0noj4|\n",
      "| 19|  red|  SUV|   0| 31.09708262147386| 52|    1|2024-07-01|tb2yi438ku6|\n",
      "+---+-----+-----+----+------------------+---+-----+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def random_date(start, end):\n",
    "    return start + timedelta(days=random.randint(0, int((end - start).days)))\n",
    "\n",
    "def random_geohash():\n",
    "    return ''.join(random.choices(string.ascii_lowercase + string.digits, k=11))\n",
    "\n",
    "data = []\n",
    "start_date = datetime(2024, 7, 1)\n",
    "end_date = datetime(2024, 7, 4)\n",
    "colors = [\"red\", \"blue\", \"green\"]\n",
    "types = [\"SUV\", \"sedan\", \"truck\"]\n",
    "\n",
    "for _ in range(1000):\n",
    "    id = _\n",
    "    color = random.choice(colors)\n",
    "    type = random.choice(types)\n",
    "    hour = random.randint(0, 4)\n",
    "    milesperhour = random.uniform(19.0, 35.0)\n",
    "    age = random.randint(40, 85)\n",
    "\n",
    "    if random.randint(1, 10) < 7:\n",
    "        if color == \"red\":\n",
    "            label = 1\n",
    "        elif color == \"blue\":\n",
    "            label = 2\n",
    "        else:\n",
    "            label = 3\n",
    "    else:\n",
    "        label = random.randint(1, 3)\n",
    "    \n",
    "    date = random_date(start_date, end_date).strftime(\"%Y-%m-%d\")\n",
    "    geohash = random_geohash()\n",
    "    data.append((id, color, type, hour, milesperhour, age, label, date, geohash))\n",
    "\n",
    "schema = [\"id\", \"color\", \"type\", \"hour\", \"milesperhour\", \"age\", \"label\", \"date\", \"geohash\"]\n",
    "data = spark.createDataFrame(data, schema)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5173f746-1d1b-40f6-93ca-593da53750a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string label\n",
    "# data = spark.createDataFrame([\n",
    "#     (0, \"red\",   \"SUV\",   12, 20.0, 60, \"class1\", \"2024-07-01\", \"u4pruydqqvj\"),\n",
    "#     (1, \"red\",   \"sedan\",  9, 30.0, 70, \"class2\", \"2024-07-02\", \"u4pruydqqvk\"),\n",
    "#     (2, \"red\",   \"truck\", 15, 25.0, 80, \"class3\", \"2024-07-01\", \"u4pruydqqvj\"),\n",
    "#     (3, \"blue\",  \"SUV\",   20, 22.0, 65, \"class1\", \"2024-07-02\", \"u4pruydqqvk\"),\n",
    "#     (4, \"blue\",  \"sedan\",  5, 35.0, 75, \"class1\", \"2024-07-01\", \"u4pruydqqvj\"),\n",
    "#     (5, \"blue\",  \"truck\", 12, 28.0, 85, \"class3\", \"2024-07-02\", \"u4pruydqqvk\"),\n",
    "#     (6, \"green\", \"SUV\",    9, 19.0, 50, \"class2\", \"2024-07-03\", \"u4pruydqqvl\"),\n",
    "#     (7, \"green\", \"sedan\", 15, 32.0, 60, \"class3\", \"2024-07-03\", \"u4pruydqqvm\"),\n",
    "#     (8, \"green\", \"truck\", 20, 27.0, 40, \"class1\", \"2024-07-04\", \"u4pruydqqvn\"),\n",
    "#     (9, \"green\", \"SUV\",    5, 21.0, 55, \"class2\", \"2024-07-04\", \"u4pruydqqvo\")\n",
    "# ], [\"id\", \"color\", \"type\", \"hour\", \"milesperhour\", \"age\", \"label\", \"date\", \"geohash\"])\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% test)\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# String Indexing for features\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"label\", outputCol=\"label_index\"),\n",
    "    StringIndexer(inputCol=\"color\", outputCol=\"color_index\"),\n",
    "    StringIndexer(inputCol=\"type\", outputCol=\"type_index\"),\n",
    "    StringIndexer(inputCol=\"hour\", outputCol=\"hour_index\")\n",
    "]\n",
    "\n",
    "# One-Hot Encoding for Logistic Regression (not needed for tree-based models)\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[\"color_index\", \"type_index\", \"hour_index\"],\n",
    "    outputCols=[\"color_vec\", \"type_vec\", \"hour_vec\"]\n",
    ")\n",
    "\n",
    "# Assembling Features for Logistic Regression and Naive Bayes\n",
    "assembler_lr_nb = VectorAssembler(\n",
    "    inputCols=[\"color_vec\", \"type_vec\", \"hour_vec\", \"milesperhour\", \"age\"],\n",
    "    outputCol=\"assembled_features\"\n",
    ")\n",
    "\n",
    "# Assembling Features for Tree-Based Models\n",
    "assembler_tree = VectorAssembler(\n",
    "    inputCols=[\"color_index\", \"type_index\", \"hour_index\", \"milesperhour\", \"age\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# MinMaxScaler for Logistic Regression and Naive Bayes\n",
    "scaler_lr_nb = MinMaxScaler(inputCol=\"assembled_features\", outputCol=\"features\")\n",
    "\n",
    "# Create and Fit the Pipeline for Logistic Regression and Naive Bayes\n",
    "pipeline_lr_nb = Pipeline(stages=indexers + [encoder, assembler_lr_nb, scaler_lr_nb])\n",
    "model_lr_nb = pipeline_lr_nb.fit(train_data)\n",
    "transformed_train_data_lr_nb = model_lr_nb.transform(train_data)\n",
    "transformed_test_data_lr_nb = model_lr_nb.transform(test_data)\n",
    "\n",
    "# Create and Fit the Pipeline for Tree-Based Models\n",
    "pipeline_tree = Pipeline(stages=indexers + [assembler_tree])\n",
    "model_tree = pipeline_tree.fit(train_data)\n",
    "transformed_train_data_tree = model_tree.transform(train_data)\n",
    "transformed_test_data_tree = model_tree.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e53b278-1f3a-4554-b6a3-003912e241af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '3', '1']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_nb.stages[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2020b2e6-e9cc-472b-aeed-7d479545214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    if 'assembled_features' in df.schema.names:\n",
    "        feature_attrs = df.schema['assembled_features'].metadata['ml_attr']['attrs']\n",
    "    else:\n",
    "        feature_attrs = df.schema['features'].metadata['ml_attr']['attrs']\n",
    "\n",
    "    features = []\n",
    "    for attr_type, attrs in feature_attrs.items():\n",
    "        features += attrs\n",
    "\n",
    "    # for each in sorted(features, key=lambda x: x['idx']):\n",
    "    #     print(each['idx'], each['name'])\n",
    "    \n",
    "    feature_names = [each['name'] for each in sorted(features, key=lambda x: x['idx'])]\n",
    "\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e4f377a-b2af-4af0-aa2f-b82a41f7138c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['color_vec_blue',\n",
       " 'color_vec_green',\n",
       " 'type_vec_truck',\n",
       " 'type_vec_SUV',\n",
       " 'hour_vec_4',\n",
       " 'hour_vec_3',\n",
       " 'hour_vec_1',\n",
       " 'hour_vec_2',\n",
       " 'milesperhour',\n",
       " 'age']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(transformed_train_data_lr_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0cea68b9-5d45-42a6-9931-da283100d030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['color_index', 'type_index', 'hour_index', 'milesperhour', 'age']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(transformed_train_data_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f9b1f-3d54-41f2-b6e6-71b445b3cfee",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e733e9-f6b2-42ef-a2fd-8cf836ae7fb3",
   "metadata": {},
   "source": [
    "## save and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8dcc9b5e-5e05-4b19-8041-8c41437ed57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save to local\n",
    "data_path = \"data/transformed_train_data_lr_nb/\"\n",
    "\n",
    "# save to s3\n",
    "# data_path = \"s3a://test-thama-misc-20210612/20240717-sparkml/data/transformed_train_data_lr_nb/\"\n",
    "\n",
    "transformed_train_data_lr_nb.write.partitionBy(\"date\", \"geohash\").mode('overwrite').save(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0defbede-c20a-4e91-8b71-7f245bbec36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>color</th>\n",
       "      <th>type</th>\n",
       "      <th>hour</th>\n",
       "      <th>milesperhour</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "      <th>label_index</th>\n",
       "      <th>color_index</th>\n",
       "      <th>type_index</th>\n",
       "      <th>hour_index</th>\n",
       "      <th>color_vec</th>\n",
       "      <th>type_vec</th>\n",
       "      <th>hour_vec</th>\n",
       "      <th>assembled_features</th>\n",
       "      <th>features</th>\n",
       "      <th>date</th>\n",
       "      <th>geohash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>883</td>\n",
       "      <td>green</td>\n",
       "      <td>truck</td>\n",
       "      <td>4</td>\n",
       "      <td>31.798986</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 31.79...</td>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.799...</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>c9djp8ws986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  color   type  hour  milesperhour  age  label  label_index  \\\n",
       "0  883  green  truck     4     31.798986   59      3          1.0   \n",
       "\n",
       "   color_index  type_index  hour_index   color_vec    type_vec  \\\n",
       "0          1.0         0.0         0.0  (0.0, 1.0)  (1.0, 0.0)   \n",
       "\n",
       "               hour_vec                                 assembled_features  \\\n",
       "0  (1.0, 0.0, 0.0, 0.0)  (0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 31.79...   \n",
       "\n",
       "                                            features        date      geohash  \n",
       "0  (0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.799...  2024-07-04  c9djp8ws986  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "transformed_train_data_lr_nb_loaded = spark.read.load(data_path)\n",
    "\n",
    "# print\n",
    "transformed_train_data_lr_nb_loaded.toPandas().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed02529b-a62d-4de7-9a02-2c511e1ffdd8",
   "metadata": {},
   "source": [
    "## save and load pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e7a7b8f-1ecf-40b7-880c-f9a1bcf7575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local\n",
    "pipeline_model_path = \"pipelines/model_lr_nb\"\n",
    "\n",
    "# save to s3\n",
    "# pipeline_model_path = \"s3a://test-thama-misc-20210612/20240717-sparkml/pipelines/model_lr_nb\"\n",
    "\n",
    "model_lr_nb.write().overwrite().save(pipeline_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b84677c0-d535-40ca-8aab-73a7ea731c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline\n",
    "loaded_model = PipelineModel.load(pipeline_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb015b-97f1-4b01-b0f2-e1395b57c35f",
   "metadata": {},
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6f3531c-cca9-4321-8c0b-f00cb5793f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Logistic Regression Model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "lr_model = lr.fit(transformed_train_data_lr_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161044be-e346-403b-889e-ce836d29aecb",
   "metadata": {},
   "source": [
    "## save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d80ceff-e90e-4263-9c44-7805c0a4531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local\n",
    "model_path = \"models/lr_model/\"\n",
    "\n",
    "# save to s3\n",
    "# model_path = \"s3a://test-thama-misc-20210612/20240717-sparkml/models/lr_model/\"\n",
    "\n",
    "lr_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcc353ed-f4c7-433a-80ea-3284ff168adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "lr_model = LogisticRegressionModel.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a545d8-5d6e-4e84-86bc-d7c52086c2d3",
   "metadata": {},
   "source": [
    "## interpret model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "465b0e56-a5aa-415b-af35-072c197945d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: DenseMatrix([[ 1.95362006e+00,  1.63605288e-01, -2.76989651e-01,\n",
      "              -5.16043888e-02,  3.09372788e-01,  2.10867137e-01,\n",
      "               2.49153739e-01,  2.08468315e-01,  3.66401691e-01,\n",
      "               6.18207235e-01],\n",
      "             [-1.69201551e-01,  1.66896353e+00,  2.05872674e-01,\n",
      "               3.96516014e-02, -3.53387303e-01, -3.05530031e-01,\n",
      "              -1.36584129e-01, -6.24807536e-04, -1.38313359e-01,\n",
      "              -3.92570818e-01],\n",
      "             [-1.78441851e+00, -1.83256882e+00,  7.11169769e-02,\n",
      "               1.19527874e-02,  4.40145153e-02,  9.46628932e-02,\n",
      "              -1.12569610e-01, -2.07843507e-01, -2.28088332e-01,\n",
      "              -2.25636417e-01]])\n",
      "Intercept: [-1.3216406774434617,-0.13098727058627097,1.4526279480297326]\n"
     ]
    }
   ],
   "source": [
    "# Get model coefficients and intercept for Logistic Regression\n",
    "coefficients = lr_model.coefficientMatrix\n",
    "intercept = lr_model.interceptVector\n",
    "print(f\"Coefficients: {coefficients}\")\n",
    "print(f\"Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e51b2793-848e-4dd7-afcc-62669c17caa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape = num_classes x num_features\n",
    "np.array(coefficients.toArray().tolist()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f338b574-650f-4bcf-96ac-d244eede69dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>color_vec_green</th>\n",
       "      <th>color_vec_blue</th>\n",
       "      <th>type_vec_sedan</th>\n",
       "      <th>type_vec_truck</th>\n",
       "      <th>hour_vec_1</th>\n",
       "      <th>hour_vec_4</th>\n",
       "      <th>hour_vec_0</th>\n",
       "      <th>hour_vec_3</th>\n",
       "      <th>milesperhour</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.953620</td>\n",
       "      <td>0.163605</td>\n",
       "      <td>-0.276990</td>\n",
       "      <td>-0.051604</td>\n",
       "      <td>0.309373</td>\n",
       "      <td>0.210867</td>\n",
       "      <td>0.249154</td>\n",
       "      <td>0.208468</td>\n",
       "      <td>0.366402</td>\n",
       "      <td>0.618207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.169202</td>\n",
       "      <td>1.668964</td>\n",
       "      <td>0.205873</td>\n",
       "      <td>0.039652</td>\n",
       "      <td>-0.353387</td>\n",
       "      <td>-0.305530</td>\n",
       "      <td>-0.136584</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>-0.138313</td>\n",
       "      <td>-0.392571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.784419</td>\n",
       "      <td>-1.832569</td>\n",
       "      <td>0.071117</td>\n",
       "      <td>0.011953</td>\n",
       "      <td>0.044015</td>\n",
       "      <td>0.094663</td>\n",
       "      <td>-0.112570</td>\n",
       "      <td>-0.207844</td>\n",
       "      <td>-0.228088</td>\n",
       "      <td>-0.225636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  color_vec_green  color_vec_blue  type_vec_sedan  type_vec_truck  \\\n",
       "0     3         1.953620        0.163605       -0.276990       -0.051604   \n",
       "1     2        -0.169202        1.668964        0.205873        0.039652   \n",
       "2     1        -1.784419       -1.832569        0.071117        0.011953   \n",
       "\n",
       "   hour_vec_1  hour_vec_4  hour_vec_0  hour_vec_3  milesperhour       age  \n",
       "0    0.309373    0.210867    0.249154    0.208468      0.366402  0.618207  \n",
       "1   -0.353387   -0.305530   -0.136584   -0.000625     -0.138313 -0.392571  \n",
       "2    0.044015    0.094663   -0.112570   -0.207844     -0.228088 -0.225636  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(\n",
    "    np.array(coefficients.toArray().tolist()),\n",
    "    columns=get_features(transformed_train_data_lr_nb)\n",
    ")\n",
    "\n",
    "# map label_index to label\n",
    "coef_df['label'] = loaded_model.stages[0].labels\n",
    "coef_df[['label'] + list(coef_df.columns)[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b55fe0b2-484e-41ed-922e-4cad1405d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>age</td>\n",
       "      <td>-0.225636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>color_vec_blue</td>\n",
       "      <td>-1.832569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>color_vec_green</td>\n",
       "      <td>-1.784419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>hour_vec_0</td>\n",
       "      <td>-0.112570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>hour_vec_1</td>\n",
       "      <td>0.044015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>hour_vec_3</td>\n",
       "      <td>-0.207844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>hour_vec_4</td>\n",
       "      <td>0.094663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>index</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>milesperhour</td>\n",
       "      <td>-0.228088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>type_vec_sedan</td>\n",
       "      <td>0.071117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>type_vec_truck</td>\n",
       "      <td>0.011953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>age</td>\n",
       "      <td>-0.392571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>color_vec_blue</td>\n",
       "      <td>1.668964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>color_vec_green</td>\n",
       "      <td>-0.169202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>hour_vec_0</td>\n",
       "      <td>-0.136584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>hour_vec_1</td>\n",
       "      <td>-0.353387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>hour_vec_3</td>\n",
       "      <td>-0.000625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>hour_vec_4</td>\n",
       "      <td>-0.305530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>index</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>milesperhour</td>\n",
       "      <td>-0.138313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>type_vec_sedan</td>\n",
       "      <td>0.205873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>type_vec_truck</td>\n",
       "      <td>0.039652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>age</td>\n",
       "      <td>0.618207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>color_vec_blue</td>\n",
       "      <td>0.163605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>color_vec_green</td>\n",
       "      <td>1.953620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>hour_vec_0</td>\n",
       "      <td>0.249154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>hour_vec_1</td>\n",
       "      <td>0.309373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>hour_vec_3</td>\n",
       "      <td>0.208468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>hour_vec_4</td>\n",
       "      <td>0.210867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>index</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>milesperhour</td>\n",
       "      <td>0.366402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>type_vec_sedan</td>\n",
       "      <td>-0.276990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>type_vec_truck</td>\n",
       "      <td>-0.051604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label          feature  coefficient\n",
       "32     1              age    -0.225636\n",
       "8      1   color_vec_blue    -1.832569\n",
       "5      1  color_vec_green    -1.784419\n",
       "23     1       hour_vec_0    -0.112570\n",
       "17     1       hour_vec_1     0.044015\n",
       "26     1       hour_vec_3    -0.207844\n",
       "20     1       hour_vec_4     0.094663\n",
       "2      1            index     2.000000\n",
       "29     1     milesperhour    -0.228088\n",
       "11     1   type_vec_sedan     0.071117\n",
       "14     1   type_vec_truck     0.011953\n",
       "31     2              age    -0.392571\n",
       "7      2   color_vec_blue     1.668964\n",
       "4      2  color_vec_green    -0.169202\n",
       "22     2       hour_vec_0    -0.136584\n",
       "16     2       hour_vec_1    -0.353387\n",
       "25     2       hour_vec_3    -0.000625\n",
       "19     2       hour_vec_4    -0.305530\n",
       "1      2            index     1.000000\n",
       "28     2     milesperhour    -0.138313\n",
       "10     2   type_vec_sedan     0.205873\n",
       "13     2   type_vec_truck     0.039652\n",
       "30     3              age     0.618207\n",
       "6      3   color_vec_blue     0.163605\n",
       "3      3  color_vec_green     1.953620\n",
       "21     3       hour_vec_0     0.249154\n",
       "15     3       hour_vec_1     0.309373\n",
       "24     3       hour_vec_3     0.208468\n",
       "18     3       hour_vec_4     0.210867\n",
       "0      3            index     0.000000\n",
       "27     3     milesperhour     0.366402\n",
       "9      3   type_vec_sedan    -0.276990\n",
       "12     3   type_vec_truck    -0.051604"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df2 = coef_df.reset_index().melt(id_vars=['label'], var_name='feature', value_name='coefficient')\n",
    "coef_df2[['label', 'feature', 'coefficient']].sort_values(by=['label', 'feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b702a-b016-4f92-94ce-ce66692df134",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ceda200-66c7-482f-bf79-db7c00b1ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize evaluators for all models\n",
    "# evaluator_accuracy = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"accuracy\")\n",
    "# evaluator_precision = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"weightedPrecision\")\n",
    "# evaluator_recall = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"weightedRecall\")\n",
    "# evaluator_f1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_index\", metricName=\"f1\")\n",
    "\n",
    "# Initialize evaluators for all models\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedRecall\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e6daa0c-5743-486a-9ddd-49cea37f9195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7014218009478673\n",
      "Logistic Regression Precision: 0.7123299902820629\n",
      "Logistic Regression Recall: 0.7014218009478672\n",
      "Logistic Regression F1 Score: 0.702552651112263\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Logistic Regression Model\n",
    "lr_predictions = lr_model.transform(transformed_test_data_lr_nb)\n",
    "lr_accuracy = evaluator_accuracy.evaluate(lr_predictions)\n",
    "lr_precision = evaluator_precision.evaluate(lr_predictions)\n",
    "lr_recall = evaluator_recall.evaluate(lr_predictions)\n",
    "lr_f1 = evaluator_f1.evaluate(lr_predictions)\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy}\")\n",
    "print(f\"Logistic Regression Precision: {lr_precision}\")\n",
    "print(f\"Logistic Regression Recall: {lr_recall}\")\n",
    "print(f\"Logistic Regression F1 Score: {lr_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef4f13-b7e8-4170-b9d1-b003c1db594a",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc3c8-6f05-41e8-8ad8-145e5b75b3db",
   "metadata": {},
   "source": [
    "## save and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddf93b27-fe3e-46d4-9319-911a4f23554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local\n",
    "data_path = \"data/transformed_train_data_tree/\"\n",
    "\n",
    "# save to s3\n",
    "# data_path = \"s3a://test-thama-misc-20210612/20240717-sparkml/data/transformed_train_data_tree/\"\n",
    "\n",
    "transformed_train_data_tree.write.partitionBy(\"date\", \"geohash\").mode('overwrite').save(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "822d8429-db42-4e16-9ea6-24746c84d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "transformed_train_data_tree_loaded = spark.read.load(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f1748c-58c8-407c-be71-27e7898889ae",
   "metadata": {},
   "source": [
    "## save and load pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4c16263-cd80-4130-b758-fc9c2e026e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local\n",
    "pipeline_model_path = \"pipelines/model_tree\"\n",
    "\n",
    "# save to s3\n",
    "# pipeline_model_path = \"s3a://test-thama-misc-20210612/20240717-sparkml/pipelines/model_tree\"\n",
    "\n",
    "model_tree.write().overwrite().save(pipeline_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa44a5e6-2e5b-4ad5-8084-22eb26a24d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline\n",
    "loaded_model = PipelineModel.load(pipeline_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a441659-18ae-4a43-a0ce-c68dc2c9d5df",
   "metadata": {},
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04d809de-ac10-4f03-9f1b-12945e87bf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/19 10:07:21 WARN DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 9 (= number of training instances)\n"
     ]
    }
   ],
   "source": [
    "# Training the Random Forest Classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label_index\")\n",
    "rf_model = rf.fit(transformed_train_data_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ff62b-afca-4de5-a86d-1cb63ef92f4e",
   "metadata": {},
   "source": [
    "## save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7dcc396e-3531-45b9-8f18-69803aa7f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local\n",
    "model_path = \"models/rf_model/\"\n",
    "\n",
    "# save to s3\n",
    "# model_path = \"s3a://test-thama-misc-20210612/20240717-sparkml/models/rf_model/\"\n",
    "\n",
    "rf_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5fb66297-ccbf-4048-8ac3-9fd75d9d7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "rf_model = RandomForestClassificationModel.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b6d98b-ff38-470c-abbe-a69f19debc82",
   "metadata": {},
   "source": [
    "## interpret model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d787dddf-49b5-472d-ad56-b09920cd23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances for Random Forest\n",
    "rf_feature_importances = rf_model.featureImportances.toArray()\n",
    "features_importances_rf = [(assembler_tree.getInputCols()[i], float(rf_feature_importances[i])) for i in range(len(rf_feature_importances))]\n",
    "importances_df_rf = pd.DataFrame(features_importances_rf, columns=[\"Feature\", \"Importance\"]).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a38850c-d279-4abe-b2e9-2ebb8cf70227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>color_index</td>\n",
       "      <td>0.301543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>milesperhour</td>\n",
       "      <td>0.298617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hour_index</td>\n",
       "      <td>0.258801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type_index</td>\n",
       "      <td>0.075918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>0.065121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Importance\n",
       "0   color_index    0.301543\n",
       "3  milesperhour    0.298617\n",
       "2    hour_index    0.258801\n",
       "1    type_index    0.075918\n",
       "4           age    0.065121"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances_df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6e3ac-b053-4ed3-8f5b-6e4d1968c9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
